{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import glob\n",
    "\n",
    "try:\n",
    "    import h5py\n",
    "except:\n",
    "    !sudo pip install h5py\n",
    "\n",
    "import sys\n",
    "PATH_TO_CODE = '../code/'\n",
    "sys.path.append(os.path.abspath(PATH_TO_CODE))\n",
    "\n",
    "from kinematics_decoding import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and select 200 trajectories of each class\n",
    "with h5py.File('../dataset/pcr_dataset_train.hdf5', 'r') as dataset:\n",
    "    labels = dataset['label'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1219)\n",
    "num_traj = 200\n",
    "idx_set = []\n",
    "for char_id in range(1, 21):\n",
    "    char_idx = np.argwhere(labels == char_id).flatten()\n",
    "    char_selected_idx = np.random.choice(char_idx, num_traj)\n",
    "    idx_set.append(char_selected_idx)\n",
    "    \n",
    "idx_set = np.asarray(idx_set).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../dataset/pcr_dataset_train.hdf5', 'r') as dataset:\n",
    "    spindle_firing = dataset['spindle_firing'][()][idx_set]\n",
    "    muscle_coords = dataset['muscle_coords'][()][idx_set]\n",
    "    joint_coords = dataset['joint_coords'][()][idx_set]\n",
    "    endeff_coords = dataset['endeffector_coords'][()][idx_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spindle_rdm = compute_rdm(spindle_firing)\n",
    "muscle_rdm = compute_rdm(muscle_coords)\n",
    "joint_rdm = compute_rdm(joint_coords)\n",
    "endeff_rdm = compute_rdm(endeff_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'spindle_firing': spindle_rdm,\n",
    "           'muscle_coords': muscle_rdm,\n",
    "           'endeffector_coords': endeff_rdm,\n",
    "           'joint_coords': joint_rdm}\n",
    "           \n",
    "pickle.dump(results, open('kinematics_rdms.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Models, Generate Representations, RDMs and save.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = pickle.load(open('../nn-training/analyzed_convmodels.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(all_models.shape[0]):\n",
    "    mymodel = load_model(all_models.iloc[i], 4, 'conv', all_models['is_trained'].iloc[i])\n",
    "    generate_layerwise_representations(mymodel, spindle_firing, 200, 'rdm')\n",
    "\n",
    "    with open('progress.txt', 'a+') as f:\n",
    "        f.write(f'Finished generating representations for model {i}/20 \\n')\n",
    "        f.write(f'Time: {time.ctime()}\\n')\n",
    "\n",
    "    layerlist = glob.glob(os.path.join(mymodel.model_path, 'rdm_*'))\n",
    "    model_results = {}\n",
    "    for layerfile in layerlist:\n",
    "        layername = os.path.basename(layerfile)[4:-5]\n",
    "        layer_rdm = compute_rdm(get_representations(layerfile))        \n",
    "        model_results[layername] = layer_rdm\n",
    "        os.remove(layerfile)\n",
    "\n",
    "    with open('progress.txt', 'a+') as f:\n",
    "        f.write(f'Finished generating RDMs for model {i}/20 \\n')\n",
    "        f.write(f'Time: {time.ctime()}\\n')\n",
    "\n",
    "    results_file = os.path.join(mymodel.model_path, 'model_rdm.p')\n",
    "    pickle.dump(model_results, open(results_file, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
