{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Tuning Curve Fit\n",
    "\n",
    "This script should be run using the libraries from the environment.yml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'tensorflow.python.tools'\n",
      "proceeding without savelouts , this will only work if no data is being generated\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, os, argparse\n",
    "import multiprocessing as mp\n",
    "import h5py\n",
    "import matplotlib\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from rowwise_neuron_curves import lstring, read_layer_reps\n",
    "from main import RunInfo\n",
    "from rowwise_neuron_curves import compute_metrics, lstring, get_binidx, get_centers, unit_vector, \\\n",
    "    angle_xaxis, get_polar, linreg, feature_set, X_data\n",
    "\n",
    "# GLOBAL PARS\n",
    "t_stride = 2\n",
    "ntime=320\n",
    "metrics = ['RMSE', 'r2', 'PCC']\n",
    "nmetrics = len(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify which model, run config, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelinfo = dict({'type': 'S',\n",
    "        'typename': 'spatial_temporal',\n",
    "        'base': 'spatial_temporal_4_8-16-16-32_32-32-64-64_7293',\n",
    "        'name': 'spatial_temporal_4_8-16-16-32_32-32-64-64_7293_1',\n",
    "        'base_regression': 'spatial_temporal_r_4_8-16-16-32_32-32-64-64_7293',\n",
    "        'nlayers': 8,\n",
    "        'max_nlayers': 8,\n",
    "        'max_act': 14, #this can be manually adjusted as the maximum in the preferred direction histogram\n",
    "        'control': False,\n",
    "        'cmap': matplotlib.colors.ListedColormap(['midnightblue']),\n",
    "        'color': 'midnightblue',\n",
    "        'regression_color': 'darkturquoise',\n",
    "        'control_cmap': 'Greys_r',\n",
    "        'regression_cmap': matplotlib.colors.ListedColormap(['darkturquoise']),\n",
    "        's_stride': 2,\n",
    "        't_stride': 3,\n",
    "        'regression_task': False,\n",
    "        'model_path': None,\n",
    "        'exp_id': None,})\n",
    "\n",
    "runinfo = RunInfo({'expid': 402, #internal experiment id\n",
    "                   'datafraction': 'auto',  #fraction (0,1] or 'auto' (i.e. if you want to run a new analysis but keep the old results that it would otherwise overwrite, increment by 1)\n",
    "                   'randomseed': 2000,\n",
    "                   'randomseed_traintest': 42,\n",
    "                   'dirr2threshold': 0.2,\n",
    "                   'verbose': 2, #0 (least), 1, 2 (most)\n",
    "                   'model_experiment_id': 22,  #used in model training, int or 'auto'\n",
    "                   'basefolder': '/media/data/DeepDraw/revisions/analysis-data/', ## change this folder to redirect to where the data is saved locally\n",
    "                   'batchsize': 100, #for layer representation generation\n",
    "                   'default_run': True, #only variable that is 'trial'-dependent,\n",
    "                                    #ie should be changed when rerunning stuff in same folder\n",
    "                                    #not semantically important for run info\n",
    "                    'dpi': 500,\n",
    "                    'orientation': 'hor',\n",
    "                    'height': 'all',\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify which layer and feature set you want to compute the tuning curves for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilayer = 2\n",
    "fset='dir' #options: ['dir', 'vel', 'dirvel', 'acc', 'labels', 'ee', 'eepolar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get kinematic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = modelinfo['name']\n",
    "nlayers = modelinfo['nlayers']\n",
    "base = modelinfo['base']\n",
    "layer = lstring(ilayer)\n",
    "expid = runinfo['expid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/data/DeepDraw/revisions/analysis-data/exp402/data/spatial_temporal_4_8-16-16-32_32-32-64-64_7293/spatial_temporal_4_8-16-16-32_32-32-64-64_7293_1\n",
      "using alternate method for accessing kinvars files by directly accessing needed arrays (pandas causes error)\n",
      "1256960\n",
      "(1964, 2, 320)\n"
     ]
    }
   ],
   "source": [
    "X, xyplmvt = X_data(fset, runinfo, datafolder=runinfo.datafolder(modelinfo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read layer represenations. shape:  (4000, 4, 320, 16)\n"
     ]
    }
   ],
   "source": [
    "lo = read_layer_reps(ilayer, runinfo, modelinfo)\n",
    "lo = lo[xyplmvt]\n",
    "\n",
    "centers = get_centers(lo.shape[2], ilayer, modelinfo)\n",
    "\n",
    "if (fset == 'vel' or fset == 'acc' or fset == 'eepolar' or fset == 'ang' or fset=='angvel' or fset=='ee' or fset == 'dir'):\n",
    "    nmods = 4\n",
    "    nmets = 6\n",
    "elif (fset == 'labels'):\n",
    "    nmods = 1\n",
    "    nmets = 1\n",
    "else:\n",
    "    assert False, 'invalid f_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = lo\n",
    "\n",
    "# Resize Y so that feature maps are appended as new rows in first feature map\n",
    "Y = Y.swapaxes(1,2).reshape((Y.shape[0], Y.shape[2], -1)).swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainevals =  np.empty((Y.shape[1], nmods, nmets))\n",
    "testevals = np.empty((Y.shape[1], nmods, nmets))\n",
    "    #Axis 0-k: lo dims except time\n",
    "    #Axis k+1: (0) LinReg (1) Dir Tuning (2) Vel Tuning (3) Dir + Vel Tuning\n",
    "    #Axis k+2: (0) RMSE (1) r2 (2) PCC (3-5) Reg Coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% DIRECTION AND VELOCITY TUNING \n",
    "def tune_row_vel(X, Y, isPolar = True):\n",
    "    ''' Fit tuning curves for a single neuron / unit (\"row\") for velocity inputs (and similar kinematic features) for four different kinds of models\n",
    "        1. simple linear regression over input features of X\n",
    "        2. Directional tuning curves\n",
    "        3. Velocity / Speed Dependence\n",
    "        4. Direction x Velocity tuning curve\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    X : np.array [nr of samples, 2] \n",
    "    Y : np.array [nr of samples]\n",
    "    row : int, row index\n",
    "    isPolar : bool, is result already boolean?\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of \n",
    "        row : int, row index\n",
    "        rowtraineval : np.array [4, 6] for four different model types. Cols 0-2: Metrics from compute_metrics, Cols 3-5: Linear Regression coeffs\n",
    "        rowtesteval : np.array [4, 6] for four different model types. Cols 0-2: Metrics from compute_metrics, Cols 3-5: Linear regression coeffs\n",
    "    '''\n",
    "    \n",
    "    rowtraineval = np.zeros((4,6))\n",
    "    rowtesteval = np.zeros((4,6))\n",
    "    #Axis 0: (0) training set (1) test set\n",
    "    #test set els 4-6: linear regression coeffs\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "\n",
    "    ##BASELINE LINREG MODEL\n",
    "    print(\"Baseline Linear Regression Model:\")\n",
    "    #Xtform_train = np.c_[X_train[:,0], X_train[:,1], np.ones_like(X_train[:,0])]\n",
    "    #Xtform_test = np.c_[X_test[:,0], X_test[:,1], np.ones_like(X_test[:,0])]\n",
    "    Xtform_train, Xtform_test, Ytform_train, Ytform_test = feature_set(\n",
    "            (X_train, np.ones_like(X_train[:,0])),\n",
    "            (X_test, np.ones_like(X_test[:,0])),\n",
    "            Y_train,\n",
    "            Y_test\n",
    "            )\n",
    "\n",
    "    rowtraineval[0], rowtesteval[0] = linreg(Xtform_train, Xtform_test, Ytform_train, Ytform_test)\n",
    "    \n",
    "    #Change to polar coordinates\n",
    "    if(not isPolar):\n",
    "        print(\"converting to polar...\")\n",
    "        X_train = get_polar(X_train)\n",
    "        X_test = get_polar(X_test)\n",
    "    \n",
    "    ##DIR DEP\n",
    "    print(\"Directional Dependence:\")\n",
    "    #Xtform_train = np.c_[np.cos(X_train[:,1]), np.sin(X_train[:,1]), np.ones_like(X_train[:,1])]\n",
    "    #Xtform_test = np.c_[np.cos(X_test[:,1]), np.sin(X_test[:,1]), np.ones_like(X_test[:,1])]\n",
    "    Xtform_train, Xtform_test, Ytform_train, Ytform_test = feature_set(\n",
    "        (np.cos(X_train[:,1]), np.sin(X_train[:,1]), np.ones_like(X_train[:,0])),\n",
    "        (np.cos(X_test[:,1]), np.sin(X_test[:,1]), np.ones_like(X_test[:,0])),\n",
    "        Y_train,\n",
    "        Y_test\n",
    "        )\n",
    "\n",
    "    rowtraineval[1], rowtesteval[1] = linreg(Xtform_train, Xtform_test, Ytform_train, Ytform_test)\n",
    "    \n",
    "    ##VEL DEP\n",
    "    \n",
    "    #Xtform_train = np.c_[X_train[:,0], np.ones_like(X_train[:,0])]\n",
    "    #Xtform_test = np.c_[X_test[:,0], np.ones_like(X_test[:,0])]\n",
    "    print(\"Velocity Dependence:\")\n",
    "    Xtform_train, Xtform_test, Ytform_train, Ytform_test = feature_set(\n",
    "        (X_train[:,0], np.ones_like(X_train[:,0])),\n",
    "        (X_test[:,0], np.ones_like(X_test[:,0])),\n",
    "        Y_train,\n",
    "        Y_test\n",
    "        )\n",
    "    rowtraineval[2], rowtesteval[2] = linreg(Xtform_train, Xtform_test, Ytform_train, Ytform_test)\n",
    "    \n",
    "    ##DIR PLUS VEL DEP\n",
    "    #Xtform_train = np.c_[X_train[:,0] * np.cos(X_train[:,1]), X_train[:,0] * np.sin(X_train[:,1]), np.ones_like(X_train[:,0])]\n",
    "    #Xtform_test = np.c_[X_test[:,0] * np.cos(X_test[:,1]), X_test[:,0] * np.sin(X_test[:,1]), np.ones_like(X_test[:,0])]\n",
    "    print(\"Direction + Velocity Dependence:\")   \n",
    "    Xtform_train, Xtform_test, Ytform_train, Ytform_test = feature_set(\n",
    "        (X_train[:,0] * np.cos(X_train[:,1]), X_train[:,0] * np.sin(X_train[:,1]), np.ones_like(X_train[:,0])),\n",
    "        (X_test[:,0] * np.cos(X_test[:,1]), X_test[:,0] * np.sin(X_test[:,1]), np.ones_like(X_test[:,0])),\n",
    "        Y_train,\n",
    "        Y_test\n",
    "        )\n",
    "    \n",
    "    rowtraineval[3], rowtesteval[3] = linreg(Xtform_train, Xtform_test, Ytform_train, Ytform_test)\n",
    "        \n",
    "    return (rowtraineval, rowtesteval)\n",
    "\n",
    "# %% LABEL SPECIFICITY\n",
    "    \n",
    "def tune_row_label(X, Y):\n",
    "    \"\"\"Calculate label specificity based on ROC AUC score based on Linear SVMs \n",
    "    trained according to a OneVsRest strategy\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    X: labels\n",
    "    Y: node activitiy for each sample\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    np.array([(nodetraineval-0.5)*2]), np.array([(nodetesteval-0.5)*2]): \n",
    "        np.array of floats [1,], return normalized ROC AUC score for given node\n",
    "    \"\"\"\n",
    "    \n",
    "    X = label_binarize(X, np.unique(X))\n",
    "    Y = Y.reshape(-1,1)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    try:\n",
    "        svm = OneVsRestClassifier(LinearSVC(max_iter=10, verbose=0))\n",
    "        svm.fit(Y_train, X_train)\n",
    "        \n",
    "        nodetraineval = roc_auc_score(X_train, svm.decision_function(Y_train))\n",
    "        try:\n",
    "            nodetesteval = roc_auc_score(X_test, svm.decision_function(Y_test))\n",
    "        except ValueError as err:\n",
    "            print(\"test evaluation failed. %s\" %err) \n",
    "            nodetesteval = 0.5\n",
    "            \n",
    "    except ValueError as err:\n",
    "         print(\"fitting SVM failed. %s\" %err) \n",
    "         nodetraineval = 0.5\n",
    "        \n",
    "    print(\"Train eval: %s\" %str(nodetraineval))\n",
    "    print(\"Test eval: %s\" %str(nodetesteval))\n",
    "    \n",
    "    return np.array([(nodetraineval-0.5)*2]), np.array([(nodetesteval-0.5)*2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row:  0\n",
      "Row:  1\n",
      "Row:  2\n",
      "Row:  3\n",
      "Row:  4\n",
      "Row:  5\n",
      "Row:  6\n",
      "Row:  7\n",
      "Row:  8\n",
      "Row:  9\n",
      "Row:  10\n",
      "Row:  11\n",
      "Row:  12\n",
      "Row:  13\n",
      "Row:  14\n",
      "Row:  15\n",
      "Row:  16\n",
      "Row:  17\n",
      "Row:  18\n",
      "Row:  19\n",
      "Row:  20\n",
      "Row:  21\n",
      "Row:  22\n",
      "Row:  23\n",
      "Row:  24\n",
      "Row:  25\n",
      "Row:  26\n",
      "Row:  27\n",
      "Row:  28\n",
      "Row:  29\n",
      "Row:  30\n",
      "Row:  31\n",
      "Row:  32\n",
      "Row:  33\n",
      "Row:  34\n",
      "Row:  35\n",
      "Row:  36\n",
      "Row:  37\n",
      "Row:  38\n",
      "Row:  39\n",
      "Row:  40\n",
      "Row:  41\n",
      "Row:  42\n",
      "Row:  43\n",
      "Row:  44\n",
      "Row:  45\n",
      "Row:  46\n",
      "Row:  47\n",
      "Row:  48\n",
      "Row:  49\n",
      "Row:  50\n",
      "Row:  51\n",
      "Row:  52\n",
      "Row:  53\n",
      "Row:  54\n",
      "Row:  55\n",
      "Row:  56\n",
      "Row:  57\n",
      "Row:  58\n",
      "Row:  59\n",
      "Row:  60\n",
      "Row:  61\n",
      "Row:  62\n",
      "Row:  63\n"
     ]
    }
   ],
   "source": [
    "for irow in range(Y.shape[1]):\n",
    "    print(\"Row: \", irow)\n",
    "\n",
    "    if(len(X.shape) > 1):\n",
    "        x = X[..., centers]\n",
    "    else:\n",
    "        x = X\n",
    "\n",
    "    y = Y[:,irow]\n",
    "\n",
    "    ##RESHAPE FOR LINEAR REGRESSION\n",
    "\n",
    "    if len(x.shape) > 1: ##FOR TIME-BASED DATA ( 2 COMPS PER TIMESPACE IS USE CASE)\n",
    "\n",
    "        tcoff = sum(np.where(centers <= 32, True, False))\n",
    "        x = x[...,tcoff:ntime-tcoff]\n",
    "        y = y[:,tcoff:ntime-tcoff]\n",
    "        x = x.swapaxes(1,2).reshape((-1,2))\n",
    "    elif fset == 'labels':\n",
    "        temp = np.ones_like(y)\n",
    "        x = (temp.swapaxes(0,1) * x).swapaxes(0,1)\n",
    "        x = x.reshape((-1,))\n",
    "    y = y.reshape((-1,))\n",
    "\n",
    "    if fset == 'acc' or fset == 'vel' or fset == 'eepolar' or fset == 'ang' or fset=='angvel' :\n",
    "        trainevals[irow], testevals[irow] = tune_row_vel(x,y, True)\n",
    "    elif fset == 'ee':\n",
    "        trainevals[irow], testevals[irow] = tune_row_vel(x,y, False)\n",
    "        #sys.stdout.flush()\n",
    "    elif fset == 'labels':\n",
    "        trainevals[irow], testevals[irow] = tune_row_label(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print some aggregate statistics for illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(stats):\n",
    "    \"\"\"print some aggregate statistics about the tuning strengths\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    stats : np.array of floats\n",
    "    \"\"\"\n",
    "    \n",
    "    stats = stats.flatten()\n",
    "    print('Min: %.4f' %stats.min())\n",
    "    print('Max: %.4f' %stats.max())\n",
    "    print('Mean: %.4f' %stats.mean())\n",
    "    print('25pc Quantile: %.4f' %np.quantile(stats, 0.25))\n",
    "    print('Median: %.4f' %np.quantile(stats, 0.5))\n",
    "    print('75pc Quantile: %.4f' %np.quantile(stats, 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial_temporal_4_8-16-16-32_32-32-64-64_7293_1 Layer 3: \n",
      "\n",
      "RMSE: \n",
      "Min: nan\n",
      "Max: nan\n",
      "Mean: nan\n",
      "25pc Quantile: nan\n",
      "Median: nan\n",
      "75pc Quantile: nan\n",
      "\n",
      "\n",
      "R2: \n",
      "Min: 0.0000\n",
      "Max: 2382973486990906079431681999784995771544749166977351114241131154861388307168959570808358856727180433693371174601667748650793646381061578975953292557346001152289641613754368.0000\n",
      "Mean: 6205660122372151248520005207773426488397784289003518526669612382451532049919165548980101189393699046076487433858509762111441787450681195249878366034755211334087608369152.0000\n",
      "25pc Quantile: 0.0000\n",
      "Median: 0.0000\n",
      "75pc Quantile: 0.0000\n",
      "\n",
      "\n",
      "PCC: \n",
      "Min: 0.0000\n",
      "Max: 0.0000\n",
      "Mean: 0.0000\n",
      "25pc Quantile: 0.0000\n",
      "Median: 0.0000\n",
      "75pc Quantile: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"%s Layer %d: \" %(modelinfo['name'], ilayer + 1))\n",
    "if fset != 'labels':\n",
    "    print(\"\\nRMSE: \")\n",
    "    print_statistics(testevals[:,0])\n",
    "\n",
    "    print(\"\\n\\nR2: \")\n",
    "    print_statistics(testevals[:,1])\n",
    "\n",
    "    print(\"\\n\\nPCC: \")\n",
    "    print_statistics(testevals[:,2])\n",
    "else:\n",
    "    print('\\nNormalized AUC ROC Score: ')\n",
    "    print_statistics(testevals[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
