{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, os, argparse\n",
    "import multiprocessing as mp\n",
    "import h5py\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from controls_main import RunInfo\n",
    "from rowwise_neuron_curves_controls import compute_metrics, lstring, get_binidx, get_centers, unit_vector, \\\n",
    "    angle_xaxis, get_polar, linreg, feature_set, X_data\n",
    "\n",
    "# GLOBAL PARS\n",
    "t_stride = 2\n",
    "ntime=320\n",
    "metrics = ['RMSE', 'r2', 'PCC']\n",
    "nmetrics = len(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify which model, run config, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelinfo = dict({'type': 'S',\n",
    "            'base': 'spatial_temporal_4_8-16-16-32_64-64-64-64_5272',\n",
    "            'name': 'spatial_temporal_4_8-16-16-32_64-64-64-64_5272_1',\n",
    "            'shortbase': 'Spatial-Temporal',\n",
    "            'shortname': 'Spatial-Temporal_1',\n",
    "            'nlayers': 8,\n",
    "            'max_act': 14,\n",
    "            'control': False,\n",
    "            'cmap': 'Blues_r',\n",
    "            'color': 'C0',\n",
    "            'control_cmap': 'Purples_r'})\n",
    "\n",
    "runinfo = RunInfo({'expid': 102, #internal experiment id\n",
    "                   'datafraction': 0.5,\n",
    "                   'randomseed': 2000,\n",
    "                   'randomseed_traintest': 42,\n",
    "                   'dirr2threshold': 0.2,\n",
    "                   'verbose': 0,\n",
    "                   'model_experiment_id': 4, #as per Pranav's model generation\n",
    "                   'basefolder' : '/home/kai/Dropbox/DeepDrawData/analysis-data/', #point to analysis-data folder\n",
    "                       #in DeepDrawData folder from Dropbox, include trailing slash\n",
    "                   'orientation' : 'hor',\n",
    "                   'height' : 'all'\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify which layer and feature set you want to compute the tuning curves for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilayer = 2\n",
    "fset='dir' #options: ['dir', 'vel', 'dirvel', 'acc', 'labels', 'ee', 'eepolar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get kinematic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = modelinfo['name']\n",
    "nlayers = modelinfo['nlayers']\n",
    "base = modelinfo['base']\n",
    "layer = lstring(ilayer)\n",
    "expid = runinfo['expid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/random_controls/exp102/data/spatial_temporal_4_8-16-16-32_64-64-64-64_5272/spatial_temporal_4_8-16-16-32_64-64-64-64_5272_1\n",
      "using alternate method for accessing kinvars files by directly accessing needed arrays (pandas causes error)\n"
     ]
    }
   ],
   "source": [
    "X, xyplmvt = X_data(fset, runinfo, datafolder=runinfo.datafolder(modelinfo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = pickle.load(open(os.path.join(runinfo.datafolder(modelinfo), layer + '.pkl'), 'rb'))\n",
    "lo = lo[xyplmvt]\n",
    "\n",
    "centers = get_centers(lo.shape[2])\n",
    "\n",
    "if (fset == 'vel' or fset == 'acc' or fset == 'eepolar' or fset == 'ang' or fset=='angvel' or fset=='ee'):\n",
    "    nmods = 4\n",
    "    nmets = 6\n",
    "elif (fset == 'labels'):\n",
    "    nmods = 1\n",
    "    nmets = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = lo\n",
    "\n",
    "# Resize Y so that feature maps are appended as new rows in first feature map\n",
    "Y = Y.swapaxes(1,2).reshape((Y.shape[0], Y.shape[2], -1)).swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainevals =  np.empty((Y.shape[1], nmods, nmets))\n",
    "testevals = np.empty((Y.shape[1], nmods, nmets))\n",
    "    #Axis 0-k: lo dims except time\n",
    "    #Axis k+1: (0) LinReg (1) Dir Tuning (2) Vel Tuning (3) Dir + Vel Tuning\n",
    "    #Axis k+2: (0) RMSE (1) r2 (2) PCC (3-5) Reg Coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% DIRECTION AND VELOCITY TUNING \n",
    "def tune_row_vel(X, Y, isPolar = True):\n",
    "    ''' Fit tuning curves for a single neuron / unit (\"row\") for velocity inputs (and similar kinematic features) for four different kinds of models\n",
    "        1. simple linear regression over input features of X\n",
    "        2. Directional tuning curves\n",
    "        3. Velocity / Speed Dependence\n",
    "        4. Direction x Velocity tuning curve\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    X : np.array [nr of samples, 2] \n",
    "    Y : np.array [nr of samples]\n",
    "    row : int, row index\n",
    "    isPolar : bool, is result already boolean?\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of \n",
    "        row : int, row index\n",
    "        rowtraineval : np.array [4, 6] for four different model types. Cols 0-2: Metrics from compute_metrics, Cols 3-5: Linear Regression coeffs\n",
    "        rowtesteval : np.array [4, 6] for four different model types. Cols 0-2: Metrics from compute_metrics, Cols 3-5: Linear regression coeffs\n",
    "    '''\n",
    "    \n",
    "    rowtraineval = np.zeros((4,6))\n",
    "    rowtesteval = np.zeros((4,6))\n",
    "    #Axis 0: (0) training set (1) test set\n",
    "    #test set els 4-6: linear regression coeffs\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "\n",
    "    ##BASELINE LINREG MODEL\n",
    "    print(\"Baseline Linear Regression Model:\")\n",
    "    #Xtform_train = np.c_[X_train[:,0], X_train[:,1], np.ones_like(X_train[:,0])]\n",
    "    #Xtform_test = np.c_[X_test[:,0], X_test[:,1], np.ones_like(X_test[:,0])]\n",
    "    Xtform_train, Xtform_test, Ytform_train, Ytform_test = feature_set(\n",
    "            (X_train, np.ones_like(X_train[:,0])),\n",
    "            (X_test, np.ones_like(X_test[:,0])),\n",
    "            Y_train,\n",
    "            Y_test\n",
    "            )\n",
    "\n",
    "    rowtraineval[0], rowtesteval[0] = linreg(Xtform_train, Xtform_test, Ytform_train, Ytform_test)\n",
    "    \n",
    "    #Change to polar coordinates\n",
    "    if(not isPolar):\n",
    "        print(\"converting to polar...\")\n",
    "        X_train = get_polar(X_train)\n",
    "        X_test = get_polar(X_test)\n",
    "    \n",
    "    ##DIR DEP\n",
    "    print(\"Directional Dependence:\")\n",
    "    #Xtform_train = np.c_[np.cos(X_train[:,1]), np.sin(X_train[:,1]), np.ones_like(X_train[:,1])]\n",
    "    #Xtform_test = np.c_[np.cos(X_test[:,1]), np.sin(X_test[:,1]), np.ones_like(X_test[:,1])]\n",
    "    Xtform_train, Xtform_test, Ytform_train, Ytform_test = feature_set(\n",
    "        (np.cos(X_train[:,1]), np.sin(X_train[:,1]), np.ones_like(X_train[:,0])),\n",
    "        (np.cos(X_test[:,1]), np.sin(X_test[:,1]), np.ones_like(X_test[:,0])),\n",
    "        Y_train,\n",
    "        Y_test\n",
    "        )\n",
    "\n",
    "    rowtraineval[1], rowtesteval[1] = linreg(Xtform_train, Xtform_test, Ytform_train, Ytform_test)\n",
    "    \n",
    "    ##VEL DEP\n",
    "    \n",
    "    #Xtform_train = np.c_[X_train[:,0], np.ones_like(X_train[:,0])]\n",
    "    #Xtform_test = np.c_[X_test[:,0], np.ones_like(X_test[:,0])]\n",
    "    print(\"Velocity Dependence:\")\n",
    "    Xtform_train, Xtform_test, Ytform_train, Ytform_test = feature_set(\n",
    "        (X_train[:,0], np.ones_like(X_train[:,0])),\n",
    "        (X_test[:,0], np.ones_like(X_test[:,0])),\n",
    "        Y_train,\n",
    "        Y_test\n",
    "        )\n",
    "    rowtraineval[2], rowtesteval[2] = linreg(Xtform_train, Xtform_test, Ytform_train, Ytform_test)\n",
    "    \n",
    "    ##DIR PLUS VEL DEP\n",
    "    #Xtform_train = np.c_[X_train[:,0] * np.cos(X_train[:,1]), X_train[:,0] * np.sin(X_train[:,1]), np.ones_like(X_train[:,0])]\n",
    "    #Xtform_test = np.c_[X_test[:,0] * np.cos(X_test[:,1]), X_test[:,0] * np.sin(X_test[:,1]), np.ones_like(X_test[:,0])]\n",
    "    print(\"Direction + Velocity Dependence:\")   \n",
    "    Xtform_train, Xtform_test, Ytform_train, Ytform_test = feature_set(\n",
    "        (X_train[:,0] * np.cos(X_train[:,1]), X_train[:,0] * np.sin(X_train[:,1]), np.ones_like(X_train[:,0])),\n",
    "        (X_test[:,0] * np.cos(X_test[:,1]), X_test[:,0] * np.sin(X_test[:,1]), np.ones_like(X_test[:,0])),\n",
    "        Y_train,\n",
    "        Y_test\n",
    "        )\n",
    "    \n",
    "    rowtraineval[3], rowtesteval[3] = linreg(Xtform_train, Xtform_test, Ytform_train, Ytform_test)\n",
    "        \n",
    "    return (rowtraineval, rowtesteval)\n",
    "\n",
    "# %% LABEL SPECIFICITY\n",
    "    \n",
    "def tune_row_label(X, Y):\n",
    "    \"\"\"Calculate label specificity based on ROC AUC score based on Linear SVMs \n",
    "    trained according to a OneVsRest strategy\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    X: labels\n",
    "    Y: node activitiy for each sample\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    np.array([(nodetraineval-0.5)*2]), np.array([(nodetesteval-0.5)*2]): \n",
    "        np.array of floats [1,], return normalized ROC AUC score for given node\n",
    "    \"\"\"\n",
    "    \n",
    "    X = label_binarize(X, np.unique(X))\n",
    "    Y = Y.reshape(-1,1)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    try:\n",
    "        svm = OneVsRestClassifier(LinearSVC(max_iter=10, verbose=0))\n",
    "        svm.fit(Y_train, X_train)\n",
    "        \n",
    "        nodetraineval = roc_auc_score(X_train, svm.decision_function(Y_train))\n",
    "        try:\n",
    "            nodetesteval = roc_auc_score(X_test, svm.decision_function(Y_test))\n",
    "        except ValueError as err:\n",
    "            print(\"test evaluation failed. %s\" %err) \n",
    "            nodetesteval = 0.5\n",
    "            \n",
    "    except ValueError as err:\n",
    "         print(\"fitting SVM failed. %s\" %err) \n",
    "         nodetraineval = 0.5\n",
    "        \n",
    "    print(\"Train eval: %s\" %str(nodetraineval))\n",
    "    print(\"Test eval: %s\" %str(nodetesteval))\n",
    "    \n",
    "    return np.array([(nodetraineval-0.5)*2]), np.array([(nodetesteval-0.5)*2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row:  0\n",
      "Row:  1\n",
      "Row:  2\n",
      "Row:  3\n",
      "Row:  4\n",
      "Row:  5\n",
      "Row:  6\n",
      "Row:  7\n",
      "Row:  8\n",
      "Row:  9\n",
      "Row:  10\n",
      "Row:  11\n",
      "Row:  12\n",
      "Row:  13\n",
      "Row:  14\n",
      "Row:  15\n",
      "Row:  16\n",
      "Row:  17\n",
      "Row:  18\n",
      "Row:  19\n",
      "Row:  20\n",
      "Row:  21\n",
      "Row:  22\n",
      "Row:  23\n",
      "Row:  24\n",
      "Row:  25\n",
      "Row:  26\n",
      "Row:  27\n",
      "Row:  28\n",
      "Row:  29\n",
      "Row:  30\n",
      "Row:  31\n",
      "Row:  32\n",
      "Row:  33\n",
      "Row:  34\n",
      "Row:  35\n",
      "Row:  36\n",
      "Row:  37\n",
      "Row:  38\n",
      "Row:  39\n",
      "Row:  40\n",
      "Row:  41\n",
      "Row:  42\n",
      "Row:  43\n",
      "Row:  44\n",
      "Row:  45\n",
      "Row:  46\n",
      "Row:  47\n",
      "Row:  48\n",
      "Row:  49\n",
      "Row:  50\n",
      "Row:  51\n",
      "Row:  52\n",
      "Row:  53\n",
      "Row:  54\n",
      "Row:  55\n",
      "Row:  56\n",
      "Row:  57\n",
      "Row:  58\n",
      "Row:  59\n",
      "Row:  60\n",
      "Row:  61\n",
      "Row:  62\n",
      "Row:  63\n"
     ]
    }
   ],
   "source": [
    "for irow in range(Y.shape[1]):\n",
    "    print(\"Row: \", irow)\n",
    "\n",
    "    if(len(X.shape) > 1):\n",
    "        x = X[..., centers]\n",
    "    else:\n",
    "        x = X\n",
    "\n",
    "    y = Y[:,irow]\n",
    "\n",
    "    ##RESHAPE FOR LINEAR REGRESSION\n",
    "\n",
    "    if len(x.shape) > 1: ##FOR TIME-BASED DATA ( 2 COMPS PER TIMESPACE IS USE CASE)\n",
    "\n",
    "        tcoff = sum(np.where(centers <= 32, True, False))\n",
    "        x = x[...,tcoff:ntime-tcoff]\n",
    "        y = y[:,tcoff:ntime-tcoff]\n",
    "        x = x.swapaxes(1,2).reshape((-1,2))\n",
    "    elif fset == 'labels':\n",
    "        temp = np.ones_like(y)\n",
    "        x = (temp.swapaxes(0,1) * x).swapaxes(0,1)\n",
    "        x = x.reshape((-1,))\n",
    "    y = y.reshape((-1,))\n",
    "\n",
    "    if fset == 'acc' or fset == 'vel' or fset == 'eepolar' or fset == 'ang' or fset=='angvel' :\n",
    "        trainevals[irow], testevals[irow] = tune_row_vel(x,y, True)\n",
    "    elif fset == 'ee':\n",
    "        trainevals[irow], testevals[irow] = tune_row_vel(x,y, False)\n",
    "        #sys.stdout.flush()\n",
    "    elif fset == 'labels':\n",
    "        trainevals[irow], testevals[irow] = tune_row_label(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print some aggregate statistics for illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(stats):\n",
    "    \"\"\"print some aggregate statistics about the tuning strengths\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    stats : np.array of floats\n",
    "    \"\"\"\n",
    "    \n",
    "    stats = stats.flatten()\n",
    "    print('Min: %.4f' %stats.min())\n",
    "    print('Max: %.4f' %stats.max())\n",
    "    print('Mean: %.4f' %stats.mean())\n",
    "    print('25pc Quantile: %.4f' %np.quantile(stats, 0.25))\n",
    "    print('Median: %.4f' %np.quantile(stats, 0.5))\n",
    "    print('75pc Quantile: %.4f' %np.quantile(stats, 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial_temporal_4_8-16-16-32_64-64-64-64_5272_1 Layer 3: \n",
      "\n",
      "RMSE: \n",
      "Min: -0.0085\n",
      "Max: 0.0389\n",
      "Mean: 0.0097\n",
      "25pc Quantile: 0.0046\n",
      "Median: 0.0093\n",
      "75pc Quantile: 0.0127\n",
      "\n",
      "\n",
      "R2: \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-fcb51a5e9d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nR2: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestevals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nPCC: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "print(\"%s Layer %d: \" %(modelinfo['name'], ilayer + 1))\n",
    "if fset != 'labels':\n",
    "    print(\"\\nRMSE: \")\n",
    "    print_statistics(testevals[:,0])\n",
    "\n",
    "    print(\"\\n\\nR2: \")\n",
    "    print_statistics(testevals[:,1])\n",
    "\n",
    "    print(\"\\n\\nPCC: \")\n",
    "    print_statistics(testevals[:,2])\n",
    "else:\n",
    "    print('\\nNormalized AUC ROC Score: ')\n",
    "    print_statistics(testevals[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
